# Training Pre-Processing Progress Reporting: Design

**Date**: 2025-01-16
**Status**: Design Phase
**Related**: [Problem Statement](./01-problem-statement.md)

---

## Executive Summary

**Problem**: Training reports progress during model training (epochs/batches) but is silent during 2-5 minutes of data loading, indicator computation, fuzzy generation, and feature engineering.

**Solution**: Extend the existing `TrainingProgressBridge` to capture and report progress from pre-training phases with granular visibility into each step.

**Key Insight**: **Visibility > Precision**. Users need to know "Processing TSLA [1h] - Computing RSI (15/40)" more than they need exact percentages.

---

## Design Principles

1. **Leverage Existing Infrastructure**: Use `TrainingProgressBridge` and `TrainingProgressRenderer` - don't rebuild
2. **Context-Rich Messages**: Show symbol, timeframe, indicator name, step number
3. **Granular Visibility**: Report per-indicator during computation, per-fuzzy-set during fuzzification
4. **Simple Percentages**: Pre-training â‰ˆ5%, Training â‰ˆ90%, Evaluation â‰ˆ5%
5. **Per-Symbol Flow**: Follow actual code structure (process each symbol completely before next)

---

## Current Architecture

### Existing Infrastructure (Already Working!)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LocalTrainingOrchestrator                                       â”‚
â”‚  - Coordinates training operation                               â”‚
â”‚  - Creates progress infrastructure                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ creates
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TrainingProgressBridge                                          â”‚
â”‚  - Translates training callbacks â†’ generic progress updates     â”‚
â”‚  - Methods: on_epoch(), on_batch(), on_complete()              â”‚
â”‚  - Emits to GenericProgressManager                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ updates
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GenericProgressManager                                          â”‚
â”‚  - Manages progress state (percentage, message, context)        â”‚
â”‚  - Thread-safe state updates                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ triggers
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TrainingProgressRenderer                                        â”‚
â”‚  - Formats training-specific messages                           â”‚
â”‚  - Example: "Epoch 5/100 Â· Batch 120/500 ğŸ–¥ï¸ GPU: 85%"         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ displays
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User Interface (CLI/API)                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Current Training Flow (What Gets Reported)

```
TrainingPipeline.train_strategy()
â”œâ”€ Load market data          [NO PROGRESS REPORTED]
â”œâ”€ Calculate indicators       [NO PROGRESS REPORTED]
â”œâ”€ Generate fuzzy sets        [NO PROGRESS REPORTED]
â”œâ”€ Create features            [NO PROGRESS REPORTED]
â”œâ”€ Generate labels            [NO PROGRESS REPORTED]
â”œâ”€ Combine data               [NO PROGRESS REPORTED]
â”œâ”€ Split data                 [NO PROGRESS REPORTED]
â”œâ”€ Create model               [NO PROGRESS REPORTED]
â”œâ”€ Train model                [âœ“ PROGRESS REPORTED via TrainingProgressBridge]
â”‚   â”œâ”€ Epoch 1
â”‚   â”‚   â”œâ”€ Batch 1/500
â”‚   â”‚   â”œâ”€ Batch 2/500
â”‚   â”‚   â””â”€ ...
â”‚   â””â”€ Epoch 2...
â””â”€ Evaluate model             [NO PROGRESS REPORTED]
```

**Result**: 2-5 minutes of silence before progress starts.

---

## Proposed Design

### High-Level Approach

**Extend TrainingProgressBridge with new methods** to capture pre-training progress:

```
TrainingProgressBridge (EXISTING)
â”œâ”€ on_epoch()                 [EXISTING - handles epoch completion]
â”œâ”€ on_batch()                 [EXISTING - handles batch progress]
â”œâ”€ on_complete()              [EXISTING - marks training complete]
â”œâ”€ on_symbol_processing()     [NEW - handles per-symbol steps]
â”œâ”€ on_indicator_computation() [NEW - handles per-indicator progress]
â”œâ”€ on_fuzzy_generation()      [NEW - handles per-fuzzy-set progress]
â””â”€ on_preparation_phase()     [NEW - handles data combining/splitting]
```

**Why this works**:
- Reuses existing progress infrastructure (no new systems)
- Bridge already knows how to emit to GenericProgressManager
- Renderer already knows how to format training messages
- Just need to add new message types for pre-training phases

### Granular Progress Hierarchy

The design supports **4 levels of granularity**:

```
Level 1: Symbol Level
â””â”€ "Processing AAPL (2/5)"

Level 2: Timeframe Level
â””â”€ "Processing AAPL (2/5) [1h]"

Level 3: Step Level
â””â”€ "Processing AAPL (2/5) [1h] - Computing indicators"

Level 4: Sub-Step Level (MOST GRANULAR)
â””â”€ "Processing AAPL (2/5) [1h] - Computing RSI (15/40)"
â””â”€ "Processing AAPL (2/5) [1h] - Fuzzifying macd_standard (12/40)"
```

**User Requirement**: We need **Level 4 granularity** for indicators and fuzzy sets.

### Progress Flow (After Implementation)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TrainingPipeline.train_strategy()                               â”‚
â”‚                                                                  â”‚
â”‚  for symbol in symbols:                                         â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚    â”‚ Load data                                       â”‚          â”‚
â”‚    â”‚  â†’ progress_callback("preprocessing", ...)     â”‚          â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                                  â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚    â”‚ Calculate indicators                            â”‚          â”‚
â”‚    â”‚  for indicator in indicators:                   â”‚          â”‚
â”‚    â”‚    â†’ progress_callback("indicator_computation") â”‚          â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                                  â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚    â”‚ Generate fuzzy sets                             â”‚          â”‚
â”‚    â”‚  for fuzzy_set in fuzzy_sets:                   â”‚          â”‚
â”‚    â”‚    â†’ progress_callback("fuzzy_generation")      â”‚          â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                                  â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚    â”‚ Create features                                 â”‚          â”‚
â”‚    â”‚  â†’ progress_callback("preprocessing", ...)     â”‚          â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                                  â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚    â”‚ Generate labels                                 â”‚          â”‚
â”‚    â”‚  â†’ progress_callback("preprocessing", ...)     â”‚          â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ Combine data                                    â”‚            â”‚
â”‚  â”‚  â†’ progress_callback("preparation", ...)       â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ Split data                                      â”‚            â”‚
â”‚  â”‚  â†’ progress_callback("preparation", ...)       â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ Train model (EXISTING PROGRESS)                â”‚            â”‚
â”‚  â”‚  â†’ progress_callback(epoch, batch, ...)        â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ all callbacks flow to
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LocalOrchestrator._create_progress_callback()                   â”‚
â”‚                                                                  â”‚
â”‚  Routes based on progress_type:                                â”‚
â”‚    - "indicator_computation" â†’ bridge.on_indicator_computation() â”‚
â”‚    - "fuzzy_generation" â†’ bridge.on_fuzzy_generation()          â”‚
â”‚    - "preprocessing" â†’ bridge.on_symbol_processing()            â”‚
â”‚    - "preparation" â†’ bridge.on_preparation_phase()              â”‚
â”‚    - "batch" â†’ bridge.on_batch() [EXISTING]                     â”‚
â”‚    - default â†’ bridge.on_epoch() [EXISTING]                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ delegates to
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TrainingProgressBridge                                          â”‚
â”‚                                                                  â”‚
â”‚  NEW METHODS (added):                                           â”‚
â”‚    on_symbol_processing() â†’ formats "Processing AAPL (2/5)"    â”‚
â”‚    on_indicator_computation() â†’ "Computing RSI (15/40)"         â”‚
â”‚    on_fuzzy_generation() â†’ "Fuzzifying macd_standard (12/40)"  â”‚
â”‚    on_preparation_phase() â†’ "Combining data from 5 symbols"     â”‚
â”‚                                                                  â”‚
â”‚  EXISTING METHODS (unchanged):                                  â”‚
â”‚    on_epoch() â†’ "Epoch 5/100"                                   â”‚
â”‚    on_batch() â†’ "Epoch 5/100 Â· Batch 120/500"                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ emits to
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GenericProgressManager (UNCHANGED)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ triggers
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TrainingProgressRenderer                                        â”‚
â”‚                                                                  â”‚
â”‚  ENHANCED to check context for preprocessing_step:              â”‚
â”‚    - "computing_indicator" â†’ render with timeframe + indicator  â”‚
â”‚    - "generating_fuzzy" â†’ render with timeframe + fuzzy set     â”‚
â”‚    - "preprocessing" â†’ render general step                      â”‚
â”‚    - default â†’ render epoch/batch (EXISTING)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## User Experience Transformation

### Before (3 minutes of silence)

```
[user initiates training]
[... waits 180 seconds with no feedback ...]
Epoch 1/100 Â· Batch 10/500
Epoch 1/100 Â· Batch 20/500
```

**Problems**:
- No idea what's happening for 3 minutes
- Can't tell if process is stuck or working
- Can't cancel with confidence (might be mid-operation)
- No debugging context if something fails

### After (full visibility)

```
Processing AAPL (1/5) [1h] - Loading data
Processing AAPL (1/5) [4h] - Loading data
Processing AAPL (1/5) [1d] - Loading data

Processing AAPL (1/5) [1h] - Computing RSI (1/40)
Processing AAPL (1/5) [1h] - Computing MACD (2/40)
Processing AAPL (1/5) [1h] - Computing EMA (3/40)
... [continues for all 40 indicators]

Processing AAPL (1/5) [4h] - Computing RSI (1/40)
... [continues for all timeframes]

Processing AAPL (1/5) [1h] - Fuzzifying rsi_14 (1/40)
Processing AAPL (1/5) [1h] - Fuzzifying macd_standard (2/40)
... [continues for all fuzzy sets]

Processing AAPL (1/5) - Creating features
Processing AAPL (1/5) - Generating labels

Processing TSLA (2/5) [1h] - Loading data
... [repeats for all symbols]

Combining data from 5 symbols
Splitting 15847 samples (train/val/test)
Creating model (input_dim=256)

Epoch 1/100 Â· Batch 10/500 ğŸ–¥ï¸ GPU: 85%  â† Existing progress continues seamlessly!
Epoch 1/100 Â· Batch 20/500
```

**Benefits**:
- **Zero silence** - constant feedback
- **Debugging context** - know exactly where process is
- **Cancellation confidence** - see it's responsive
- **Time estimation** - can gauge remaining time
- **Granular visibility** - symbol, timeframe, indicator name, progress counters

---

## Key Design Decisions

### Decision 1: Extend Bridge vs. New Coordinator

**Options Considered**:
- A) Create new `TrainingProgressCoordinator` to orchestrate pre-training progress
- B) Extend existing `TrainingProgressBridge` with new methods

**Decision**: **Option B - Extend TrainingProgressBridge**

**Rationale**:
- Bridge already handles progress translation (training callbacks â†’ generic progress)
- Bridge already knows how to emit to GenericProgressManager
- Adding a coordinator would be redundant - the bridge IS the coordinator
- Simpler, leverages existing patterns, less code

### Decision 2: Granularity Level

**Options Considered**:
- A) Symbol-level only: "Processing AAPL (2/5)"
- B) Step-level: "Processing AAPL (2/5) - Computing indicators"
- C) Sub-step level: "Processing AAPL (2/5) [1h] - Computing RSI (15/40)"

**Decision**: **Option C - Sub-step level for indicators and fuzzy sets**

**Rationale**:
- User explicitly requested: "which indicator is being computed, that's good information"
- Provides maximum debugging context
- Shows exact progress through long operations
- Timeframe context helps identify multi-timeframe issues

### Decision 3: Progress Percentage Allocation

**Options Considered**:
- A) Complex phase-weighted percentages (track each symbol's progress precisely)
- B) Simple allocation: Pre-training 5%, Training 90%, Evaluation 5%

**Decision**: **Option B - Simple allocation**

**Rationale**:
- User feedback: "The percentages themselves are less important"
- Training is 95% of actual wall-clock time
- Rendering visibility is more important than precise percentages
- Simpler implementation, less error-prone

### Decision 4: Implementation Strategy

**Options Considered**:

- A) Refactor how indicators/fuzzy sets are computed to enable progress hooks
- B) Add progress callbacks within existing computation loops (no refactoring)

**Decision**: **Option B - Add callbacks to existing loops**

**Rationale**:

- Current computation flow (per-symbol, per-timeframe) is correct - don't change it
- Just need to insert progress callbacks at the right points in existing loops
- `IndicatorEngine` and `FuzzyEngine` already iterate internally - hook into those iterations
- Minimal code changes, preserves existing architecture
- No performance impact, no risk of breaking existing computation logic

---

## Integration Points

### Component Changes Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TrainingProgressBridge                                     â”‚
â”‚  ADD: 4 new methods for pre-training progress              â”‚
â”‚  UNCHANGED: existing epoch/batch methods                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TrainingPipeline                                           â”‚
â”‚  train_strategy(): ADD progress callbacks at checkpoints   â”‚
â”‚  calculate_indicators(): ADD per-indicator iteration       â”‚
â”‚  generate_fuzzy_memberships(): ADD per-fuzzy-set iteration â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LocalOrchestrator + HostServiceOrchestrator                â”‚
â”‚  _create_progress_callback(): ADD routing for new types    â”‚
â”‚  (Both orchestrators need identical callback routing)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TrainingProgressRenderer                                   â”‚
â”‚  render_message(): ADD formatting for preprocessing contextâ”‚
â”‚  UNCHANGED: existing epoch/batch rendering                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ IndicatorEngine / FuzzyEngine                              â”‚
â”‚  ADD: Progress callback parameter to existing methods      â”‚
â”‚  ADD: Progress reporting within existing iteration loops   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Callback Data Flow

```
TrainingPipeline sends callback with context dict:
  {
    "progress_type": "indicator_computation",
    "symbol": "AAPL",
    "symbol_index": 2,
    "total_symbols": 5,
    "timeframe": "1h",
    "indicator_name": "RSI",
    "indicator_index": 15,
    "total_indicators": 40
  }
         â†“
Orchestrator routes to bridge method
  (LocalOrchestrator OR HostServiceOrchestrator)
  (Both need identical routing logic for new progress types)
         â†“
TrainingProgressBridge.on_indicator_computation()
  - Formats message: "Processing AAPL (2/5) [1h] - Computing RSI (15/40)"
  - Calculates percentage: ~2.3% (within 0-5% pre-training range)
  - Emits to GenericProgressManager
         â†“
GenericProgressManager updates state
         â†“
TrainingProgressRenderer formats final display
         â†“
User sees: "Processing AAPL (2/5) [1h] - Computing RSI (15/40)"
```

**Important**: Both `LocalOrchestrator` and `HostServiceOrchestrator` need the same callback routing updates since both call `TrainingPipeline.train_strategy()`. The change is minor since all the real work happens in TrainingPipeline - the orchestrators just route callbacks to the bridge.

---

## What Stays the Same

**Critical**: This design **extends** existing infrastructure, doesn't replace it.

- âœ“ Existing epoch/batch progress reporting (UNCHANGED)
- âœ“ TrainingProgressBridge.on_epoch() and on_batch() (UNCHANGED)
- âœ“ TrainingProgressRenderer epoch/batch formatting (UNCHANGED)
- âœ“ GenericProgressManager (UNCHANGED)
- âœ“ OperationsService integration (UNCHANGED)
- âœ“ Cancellation token support (UNCHANGED)
- âœ“ ServiceOrchestrator patterns (UNCHANGED)

**The existing training progress continues to work exactly as before!**

---

## Next Steps

See [03-architecture.md](./03-architecture.md) for detailed architecture and [04-implementation-plan.md](./04-implementation-plan.md) for implementation tasks.

---

**END OF DESIGN DOCUMENT**
